{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto de pruebas A/B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1️ Objetivo\n",
    "\n",
    "Evaluar si el nuevo sistema de recomendaciones mejora el rendimiento del embudo de conversión:  \n",
    "`product_page → product_card → purchase`.\n",
    "\n",
    "### 2️ Hipótesis\n",
    "\n",
    "* **H₀ (nula):** No hay diferencia significativa entre los grupos A y B en las tasas de conversión del embudo.  \n",
    "* **H₁ (alternativa):** El grupo B (nuevo embudo) tiene una conversión al menos **10% superior** en cada etapa (`product_page`, `product_card`, `purchase`).\n",
    "\n",
    "### 3️ Diseño del experimento\n",
    "\n",
    "* **Grupos:**\n",
    "  * A — control (embudo actual)\n",
    "  * B — experimental (nuevo embudo con sistema de recomendación)\n",
    "* **Audiencia:** 15% de los nuevos usuarios en la UE\n",
    "* **Periodo:**\n",
    "  * Inicio: 2020-12-07\n",
    "  * Cierre de nuevos usuarios: 2020-12-21\n",
    "  * Fin total: 2021-01-01\n",
    "* **Duración efectiva de observación:** 14 días por usuario desde la inscripción.\n",
    "\n",
    "### 4️ Métricas clave\n",
    "\n",
    "* **Eventos:**\n",
    "  * `product_page` (vistas de producto)\n",
    "  * `product_card` (añadir al carrito)\n",
    "  * `purchase` (compra completada)\n",
    "* **Indicadores:**\n",
    "  * Tasa de conversión por etapa\n",
    "  * Incremento relativo (%) entre grupos\n",
    "  * Prueba de significancia (z-test o Mann–Whitney según distribución)\n",
    "\n",
    "### 5️ Criterio de éxito\n",
    "\n",
    "≥ 10 % de mejora en cada etapa del embudo con significancia estadística (α = 0.05).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets cargados y columnas estandarizadas.\n"
     ]
    }
   ],
   "source": [
    "# Exploración de los datos: tipos, nulos y duplicados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt, erf\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "\n",
    "marketing = pd.read_csv(r\"C:\\Users\\pc\\OneDrive\\Documentos\\TripleTen\\Proyecto_Sprint 14\\Test AB\\ab_project_marketing_events_us.csv\")\n",
    "new_users = pd.read_csv(r\"C:\\Users\\pc\\OneDrive\\Documentos\\TripleTen\\Proyecto_Sprint 14\\Test AB\\final_ab_new_users_upd_us.csv\")\n",
    "events = pd.read_csv(r\"C:\\Users\\pc\\OneDrive\\Documentos\\TripleTen\\Proyecto_Sprint 14\\Test AB\\final_ab_events_upd_us.csv\")\n",
    "participants = pd.read_csv(r\"C:\\Users\\pc\\OneDrive\\Documentos\\TripleTen\\Proyecto_Sprint 14\\Test AB\\final_ab_participants_upd_us.csv\")\n",
    "\n",
    "for df in (marketing, new_users, events, participants):\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "print(\"Datasets cargados y columnas estandarizadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[marketing] tipos:\n",
      "name                 object\n",
      "regions              object\n",
      "start_dt     datetime64[ns]\n",
      "finish_dt    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "[new_users] tipos:\n",
      "user_id               object\n",
      "first_date    datetime64[ns]\n",
      "region                object\n",
      "device                object\n",
      "dtype: object\n",
      "\n",
      "[events] tipos:\n",
      "user_id               object\n",
      "event_dt      datetime64[ns]\n",
      "event_name            object\n",
      "details              float64\n",
      "dtype: object\n",
      "\n",
      "[participants] tipos:\n",
      "user_id    object\n",
      "group      object\n",
      "ab_test    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tipos de datos y conversión de fechas\n",
    "def convert_dates(df):\n",
    "    for c in df.columns:\n",
    "        if (\"date\" in c) or (\"dt\" in c):\n",
    "            df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "marketing = convert_dates(marketing)\n",
    "new_users = convert_dates(new_users)\n",
    "events = convert_dates(events)\n",
    "\n",
    "for name, df in {\"marketing\": marketing, \"new_users\": new_users, \"events\": events, \"participants\": participants}.items():\n",
    "    print(f\"\\n[{name}] tipos:\\n{df.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Tipos/Fechas):**  \n",
    "- Las fechas en `marketing.start_dt/finish_dt`, `new_users.first_date`, `events.event_dt` son pasadas a datatime para facilitar su analsis y intepretacion. \n",
    "- `events.details` es numérico (importe en compras); otros eventos tienen `details` nulo por diseño se mantienen no es necesario modificar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[marketing] nulos por columna:\n",
      "name         0\n",
      "regions      0\n",
      "start_dt     0\n",
      "finish_dt    0\n",
      "dtype: int64\n",
      "[marketing] duplicados (filas completas): 0\n",
      "\n",
      "[new_users] nulos por columna:\n",
      "user_id       0\n",
      "first_date    0\n",
      "region        0\n",
      "device        0\n",
      "dtype: int64\n",
      "[new_users] duplicados (filas completas): 0\n",
      "\n",
      "[events] nulos por columna:\n",
      "user_id            0\n",
      "event_dt           0\n",
      "event_name         0\n",
      "details       363447\n",
      "dtype: int64\n",
      "[events] duplicados (filas completas): 0\n",
      "\n",
      "[participants] nulos por columna:\n",
      "user_id    0\n",
      "group      0\n",
      "ab_test    0\n",
      "dtype: int64\n",
      "[participants] duplicados (filas completas): 0\n"
     ]
    }
   ],
   "source": [
    "# Nulos y duplicados\n",
    "for name, df in {\"marketing\": marketing, \"new_users\": new_users, \"events\": events, \"participants\": participants}.items():\n",
    "    print(f\"\\n[{name}] nulos por columna:\")\n",
    "    print(df.isna().sum())\n",
    "    print(f\"[{name}] duplicados (filas completas): {df.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Nulos/Duplicados):**  \n",
    "- Nulos solo en `events.details` (esperado).  \n",
    "- 0 duplicados a nivel fila en todos los datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_users: duplicados por user_id = 0\n",
      "participants: usuarios en más de un grupo = 441\n",
      "Ejemplos:\n",
      "user_id\n",
      "0082295A41A867B5    2\n",
      "00E68F103C66C1F7    2\n",
      "02313B9E82255F47    2\n",
      "04F2CF340B4F3822    2\n",
      "051D59BC38C3B3AA    2\n",
      "Name: group, dtype: int64\n",
      "events: duplicados por (user_id, event_dt, event_name) = 0\n"
     ]
    }
   ],
   "source": [
    "# Claves y contaminación\n",
    "if \"user_id\" in new_users.columns:\n",
    "    print(f\"new_users: duplicados por user_id = {new_users['user_id'].duplicated().sum()}\")\n",
    "\n",
    "if set([\"user_id\",\"ab_test\",\"group\"]).issubset(participants.columns):\n",
    "    dup_users = participants.groupby(\"user_id\")[\"group\"].nunique()\n",
    "    contamination = dup_users[dup_users > 1]\n",
    "    print(f\"participants: usuarios en más de un grupo = {len(contamination)}\")\n",
    "    if len(contamination) > 0:\n",
    "        print(\"Ejemplos:\")\n",
    "        print(contamination.head())\n",
    "\n",
    "if set([\"user_id\",\"event_dt\",\"event_name\"]).issubset(events.columns):\n",
    "    dup_events = events.duplicated(subset=[\"user_id\",\"event_dt\",\"event_name\"]).sum()\n",
    "    print(f\"events: duplicados por (user_id, event_dt, event_name) = {dup_events}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación rápida (Asignación/Claves):**  \n",
    "- No hay duplicados de `user_id` en `new_users`.  \n",
    "- Tras limpieza ya no hay contaminación entre grupos: 0.  \n",
    "- Sin duplicados por (`user_id`,`event_dt`,`event_name`) en `events`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfil de 'details' por evento:\n",
      "               total   nulos  pct_nulos\n",
      "event_name                             \n",
      "login         182465  182465      100.0\n",
      "product_cart   60120   60120      100.0\n",
      "product_page  120862  120862      100.0\n",
      "purchase       60314       0        0.0\n",
      "\n",
      "'purchase' con detalles numéricos: 60314 de 60314 (100.0%)\n",
      "\n",
      "Rango de fechas — marketing\n",
      "- start_dt: 2020-01-25 00:00:00 → 2020-12-30 00:00:00 (n_na=0)\n",
      "- finish_dt: 2020-02-07 00:00:00 → 2021-01-07 00:00:00 (n_na=0)\n",
      "\n",
      "Rango de fechas — new_users\n",
      "- first_date: 2020-12-07 00:00:00 → 2020-12-23 00:00:00 (n_na=0)\n",
      "\n",
      "Rango de fechas — events\n",
      "- event_dt: 2020-12-07 00:00:33 → 2020-12-30 23:36:33 (n_na=0)\n"
     ]
    }
   ],
   "source": [
    "# Perfil 'details' y rangos de fechas\n",
    "if \"details\" in events.columns and \"event_name\" in events.columns:\n",
    "    prof = (\n",
    "        events.assign(is_null=events[\"details\"].isna())\n",
    "              .groupby(\"event_name\")[\"is_null\"]\n",
    "              .agg(total=\"count\", nulos=\"sum\")\n",
    "              .assign(pct_nulos=lambda x: round(x[\"nulos\"]/x[\"total\"]*100, 2))\n",
    "    )\n",
    "    print(\"\\nPerfil de 'details' por evento:\")\n",
    "    print(prof)\n",
    "\n",
    "    pur = events.loc[events[\"event_name\"]==\"purchase\",\"details\"]\n",
    "    pur_num = pd.to_numeric(pur, errors=\"coerce\")\n",
    "    print(f\"\\n'purchase' con detalles numéricos: {pur_num.notna().sum()} de {len(pur)} \"\n",
    "          f\"({round(pur_num.notna().mean()*100,2)}%)\")\n",
    "\n",
    "def profile_datetime_columns(df, name):\n",
    "    dt_cols = [c for c in df.columns if np.issubdtype(df[c].dtype, np.datetime64)]\n",
    "    if not dt_cols:\n",
    "        print(f\"{name}: sin columnas datetime.\")\n",
    "        return\n",
    "    print(f\"\\nRango de fechas — {name}\")\n",
    "    for c in dt_cols:\n",
    "        print(f\"- {c}: {df[c].min()} → {df[c].max()} (n_na={df[c].isna().sum()})\")\n",
    "\n",
    "for name, df in {\"marketing\": marketing, \"new_users\": new_users, \"events\": events}.items():\n",
    "    profile_datetime_columns(df, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detalles/Fechas:**  \n",
    "- `purchase.details` 100% numérico por lo tanto se toma válido como **importe**.  \n",
    "- Eventos en rango **2020-12-07 → 2020-12-30**; el test cerraba el **2021-01-01** faltan ~2 días, solicitar explicacion porque se omitieron estos 2 dias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros listos.\n"
     ]
    }
   ],
   "source": [
    "# Validación temporal, audiencia y participantes\n",
    "TEST_NAME   = \"recommender_system_test\"\n",
    "LAUNCH      = pd.Timestamp(\"2020-12-07\")\n",
    "STOP_INTAKE = pd.Timestamp(\"2020-12-21\")   # última fecha para nuevos usuarios\n",
    "TEST_END    = pd.Timestamp(\"2021-01-01\")   # fin oficial\n",
    "WINDOW_DAYS = 14                           # ventana individual de medición\n",
    "FUNNEL_EVENTS = [\"product_page\", \"product_cart\", \"purchase\"]\n",
    "print(\"Parámetros listos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Definimos la ventana experimental y los eventos del embudo. La medición se hace por usuario: desde su `first_date` y por **14 días**, con tope en **2021-01-01**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total participantes (test): 3675 | Contaminados: 0 | Limpios: 3675\n"
     ]
    }
   ],
   "source": [
    "# Participantes del test y contaminación\n",
    "participants_test = participants.query(\"ab_test == @TEST_NAME\").copy()\n",
    "\n",
    "dup_users = participants_test.groupby(\"user_id\")[\"group\"].nunique()\n",
    "contaminated_users = dup_users[dup_users > 1].index\n",
    "participants_clean = participants_test[~participants_test[\"user_id\"].isin(contaminated_users)].copy()\n",
    "\n",
    "print(f\"Total participantes (test): {participants_test['user_id'].nunique()} | \"\n",
    "      f\"Contaminados: {len(contaminated_users)} | \"\n",
    "      f\"Limpios: {participants_clean['user_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos solo con **`participants_clean`** (excluye cualquier usuario en más de un grupo). Esto asegura asignación A/B válida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevos EU ventana: 39466 | Enrolled (EU∩A/B): 3481\n",
      "\n",
      "Balance por grupo (inscritos):\n",
      "group\n",
      "A    2604\n",
      "B     877\n",
      "Name: user_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#  Cohorte EU en ventana de enrolamiento\n",
    "new_users_eu = new_users.query(\"region == 'EU' and @LAUNCH <= first_date <= @STOP_INTAKE\").copy()\n",
    "\n",
    "# Enrolled = (nuevos EU en ventana) ∩ (asignados A/B limpios)\n",
    "enrolled = (new_users_eu[[\"user_id\",\"first_date\"]]\n",
    "            .merge(participants_clean[[\"user_id\",\"group\"]], on=\"user_id\", how=\"inner\"))\n",
    "\n",
    "print(f\"Nuevos EU ventana: {new_users_eu['user_id'].nunique()} | \"\n",
    "      f\"Enrolled (EU∩A/B): {enrolled['user_id'].nunique()}\")\n",
    "print(\"\\nBalance por grupo (inscritos):\")\n",
    "print(enrolled.groupby(\"group\")[\"user_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Análisis exploratorio (EDA)\n",
    "\n",
    "**1.- Conversión en las diferentes etapas del embudo**  \n",
    "El grupo **B** tuvo menores tasas en todas las etapas (`product_page`, `product_cart`, `purchase`).\n",
    "\n",
    "- No hubo incremento ≥10 % por lo tanto se logró.  \n",
    "- Las diferencias negativas en “page” (-13 %) y “purchase” (-11 %) fueron **estadísticamente significativas** (p < 0.05).\n",
    "\n",
    "**2.- ¿El número de eventos por usuario está distribuido equitativamente?**  \n",
    "No. El grupo **A** tiene 2604 usuarios y el grupo **B** solo 877.  \n",
    "Esa relación ≈ 3:1 genera **desequilibrio muestral**, reduciendo la potencia de las pruebas.\n",
    "\n",
    "**3.- ¿Hay usuarios presentes en ambas muestras?**  \n",
    "No. Tras la limpieza, la contaminación fue **0 usuarios**.  \n",
    "La asignación A/B esta limpia.\n",
    "\n",
    "**4.- Distribución de eventos entre los días**  \n",
    "Los eventos se registraron entre **2020-12-07 y 2020-12-30**, con actividad continua y dentro de la ventana experimental.  \n",
    "No hay fugas antes del registro ni después del 01-ene-2021 → coherente con el protocolo.\n",
    "\n",
    "**5.- Peculiaridades antes de iniciar la prueba**\n",
    "- Muestra menor de lo previsto (3481 vs 6000).\n",
    "- Cobertura 8.8 % < 15 % planificada.\n",
    "- Fuerte desbalance A/B.\n",
    "- Fechas de eventos ligeramente más cortas (faltan 2 días).  \n",
    " Todo esto debe documentarse porque afecta la representatividad y significancia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cobertura del test en nuevos EU (ventana): 8.82%  |  Target ≈ 15%\n",
      "Eventos en ventana 14d (cap 2021-01-01): 12,033\n",
      "product_page    6132\n",
      "purchase        2998\n",
      "product_cart    2903\n",
      "Name: event_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cobertura de audiencia\n",
    "den = new_users_eu[\"user_id\"].nunique()\n",
    "num = enrolled[\"user_id\"].nunique()\n",
    "coverage = (num / den) if den else np.nan\n",
    "print(f\"Cobertura del test en nuevos EU (ventana): {coverage:.2%}  |  Target ≈ 15%\")\n",
    "\n",
    "# Ventana de 14 días por usuario (cap en TEST_END)\n",
    "events_ab = events.merge(enrolled[[\"user_id\",\"first_date\",\"group\"]], on=\"user_id\", how=\"inner\")\n",
    "events_ab[\"win_end\"] = (events_ab[\"first_date\"] + pd.to_timedelta(WINDOW_DAYS, unit=\"D\")).clip(upper=TEST_END)\n",
    "\n",
    "events_in_scope = events_ab.query(\"first_date <= event_dt and event_dt < win_end\").copy()\n",
    "events_in_scope = events_in_scope[events_in_scope[\"event_name\"].isin(FUNNEL_EVENTS)]\n",
    "\n",
    "print(f\"Eventos en ventana 14d (cap {TEST_END.date()}): {len(events_in_scope):,}\")\n",
    "print(events_in_scope[\"event_name\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset reducido con tasas\n",
    "plot_df = results[[\"metric\", \"A_rate\", \"B_rate\"]].melt(id_vars=\"metric\", var_name=\"group\", value_name=\"rate\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "for i, stage in enumerate(plot_df[\"metric\"].unique()):\n",
    "    subset = plot_df[plot_df[\"metric\"]==stage]\n",
    "    plt.bar(subset[\"group\"], subset[\"rate\"], label=stage)\n",
    "    plt.title(\"Tasas de conversión por grupo y etapa del embudo\")\n",
    "    plt.ylabel(\"Tasa de conversión\")\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrastamos la **cobertura real** vs el **objetivo (15%)**. Coberturas bajas reducen potencia y pueden sesgar representatividad.\n",
    "\n",
    "Nos quedamos solo con eventos del embudo y **dentro de la ventana** definida por usuario. Esto nos evita “fugas” fuera de la medición para mayor precision de analsis .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eventos antes de la inscripción (esperado 0): 0\n",
      "Rango real de events: 2020-12-07 00:00:33 → 2020-12-30 23:36:33 | Fin planificado: 2021-01-01 00:00:00\n",
      "Listo: usa `enrolled` y `events_in_scope` para calcular embudos y conversiones por grupo.\n"
     ]
    }
   ],
   "source": [
    "# Chequeos de sanidad\n",
    "leaks = (events_ab[\"event_dt\"] < events_ab[\"first_date\"]).sum()\n",
    "print(f\"Eventos antes de la inscripción (esperado 0): {leaks}\")\n",
    "\n",
    "print(f\"Rango real de events: {events['event_dt'].min()} → {events['event_dt'].max()} | \"\n",
    "      f\"Fin planificado: {TEST_END}\")\n",
    "\n",
    "# %% Artefactos listos para embudo y métricas\n",
    "print(\"Listo: usa `enrolled` y `events_in_scope` para calcular embudos y conversiones por grupo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Fugas = 0** confirma consistencia temporal.\n",
    "    \n",
    "- Si la última fecha real < `TEST_END`, documenta la pequeña diferencia \n",
    "(no invalida, pero reduce cobertura de los últimos días).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_name        n_page  n_cart  n_purch  seen_page  add_cart  purchased\n",
      "user_id                                                                  \n",
      "001064FEAAB631A1       3       0        0          1         0          0\n",
      "0010A1C096941592       4       0        4          1         0          1\n",
      "003DF44D7589BBD4       5       5        0          1         1          0\n",
      "005E096DBD379BCF       0       0        2          0         0          1\n",
      "006E3E4E232CE760       3       0        0          1         0          0\n"
     ]
    }
   ],
   "source": [
    "# Construir flags por usuario para cada etapa del embudo \n",
    "\n",
    "# Embudo base por usuario\n",
    "FUNNEL_EVENTS = [\"product_page\", \"product_cart\", \"purchase\"]\n",
    "df = events_in_scope[events_in_scope[\"event_name\"].isin(FUNNEL_EVENTS)].copy()\n",
    "\n",
    "user_step = (\n",
    "    df.pivot_table(index=\"user_id\", columns=\"event_name\", values=\"event_dt\",\n",
    "                   aggfunc=\"count\", fill_value=0)\n",
    "      .reindex(columns=FUNNEL_EVENTS, fill_value=0)\n",
    "      .astype(int)\n",
    "      .rename(columns={\"product_page\": \"n_page\", \"product_cart\": \"n_cart\", \"purchase\": \"n_purch\"})\n",
    ")\n",
    "\n",
    "user_step[\"seen_page\"] = (user_step[\"n_page\"] > 0).astype(int)\n",
    "user_step[\"add_cart\"]  = (user_step[\"n_cart\"] > 0).astype(int)\n",
    "user_step[\"purchased\"] = (user_step[\"n_purch\"] > 0).astype(int)\n",
    "print(user_step.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos variables binarias (`seen_page`, `add_cart`, `purchased`) que indican si el usuario alcanzó cada etapa.  \n",
    "Esto permite medir tasas de conversión individuales y evitar sesgos por número de eventos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            user_id group  n_page  n_cart  n_purch  seen_page  add_cart  \\\n",
      "0  D72A72121175D8BE     A     1.0     0.0      0.0        1.0       0.0   \n",
      "1  DD4352CDCF8C3D57     B     5.0     0.0      0.0        1.0       0.0   \n",
      "2  831887FE7F2D6CBA     A     0.0     3.0      2.0        0.0       1.0   \n",
      "3  4CB179C7F847320B     B     3.0     0.0      0.0        1.0       0.0   \n",
      "4  3C5DD0288AC4FE23     A     1.0     0.0      1.0        1.0       0.0   \n",
      "\n",
      "   purchased  rev_14d  \n",
      "0        0.0     0.00  \n",
      "1        0.0     0.00  \n",
      "2        1.0   104.98  \n",
      "3        0.0     0.00  \n",
      "4        1.0     4.99  \n"
     ]
    }
   ],
   "source": [
    "# Revenue y dataset final\n",
    "rev = (\n",
    "    df.loc[df[\"event_name\"]==\"purchase\", [\"user_id\",\"details\"]]\n",
    "      .groupby(\"user_id\", as_index=False)[\"details\"].sum()\n",
    "      .rename(columns={\"details\": \"rev_14d\"})\n",
    ")\n",
    "\n",
    "user_metrics = (\n",
    "    enrolled[[\"user_id\",\"group\"]]\n",
    "      .merge(user_step.reset_index(), on=\"user_id\", how=\"left\")\n",
    "      .merge(rev, on=\"user_id\", how=\"left\")\n",
    "      .fillna(0)\n",
    ")\n",
    "print(user_metrics.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user_metrics` contiene métricas completas por usuario: grupo A/B, pasos del embudo y `rev_14d` (suma de compras).\n",
    "Pasaremos a calcular tasas y comparaciones estadísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      metric    A_rate    B_rate  lift_B_vs_A    z_stat   p_value     A_n  \\\n",
      "0  seen_page  0.647081  0.562144    -0.131263 -4.495436  0.000007  2604.0   \n",
      "0   add_cart  0.300307  0.278221    -0.073545 -1.240767  0.214692  2604.0   \n",
      "0  purchased  0.319892  0.283922    -0.112444 -1.990600  0.046525  2604.0   \n",
      "0   add_cart  0.302671  0.275862    -0.088573 -1.146252  0.251691  1685.0   \n",
      "0  purchased  0.333760  0.307377    -0.079047 -0.766645  0.443292   782.0   \n",
      "0  purchased  0.343620  0.314402    -0.085032 -1.207201  0.227355  1685.0   \n",
      "\n",
      "     B_n  \n",
      "0  877.0  \n",
      "0  877.0  \n",
      "0  877.0  \n",
      "0  493.0  \n",
      "0  244.0  \n",
      "0  493.0  \n"
     ]
    }
   ],
   "source": [
    "# Funciones auxiliares\n",
    "\n",
    "def prop_ci(p, n, z=1.96):\n",
    "    se = np.sqrt(p*(1-p)/n)\n",
    "    return (p - z*se, p + z*se)\n",
    "\n",
    "def two_prop_ztest(x1, n1, x2, n2):\n",
    "    p_pool = (x1 + x2) / (n1 + n2)\n",
    "    se = np.sqrt(p_pool*(1 - p_pool)*(1/n1 + 1/n2))\n",
    "    z = (x2/n2 - x1/n1) / se\n",
    "    Phi = lambda t: 0.5*(1 + erf(t/sqrt(2)))\n",
    "    p = 2*(1 - Phi(abs(z)))\n",
    "    return z, p\n",
    "\n",
    "# Tasas y prueba z\n",
    "def summarize_conversion(col, denom_filter=None):\n",
    "    data = user_metrics.copy()\n",
    "    if denom_filter is not None:\n",
    "        data = data[denom_filter(data)]\n",
    "    g = data.groupby(\"group\")[col].agg([\"sum\",\"count\"])\n",
    "    a, b = g.loc[\"A\"], g.loc[\"B\"]\n",
    "    pA, pB = a[\"sum\"]/a[\"count\"], b[\"sum\"]/b[\"count\"]\n",
    "    z, p = two_prop_ztest(a[\"sum\"], a[\"count\"], b[\"sum\"], b[\"count\"])\n",
    "    lift = (pB - pA)/pA\n",
    "    return pd.DataFrame({\n",
    "        \"metric\": [col],\n",
    "        \"A_rate\": [pA], \"B_rate\": [pB],\n",
    "        \"lift_B_vs_A\": [lift],\n",
    "        \"z_stat\": [z], \"p_value\": [p],\n",
    "        \"A_n\": [a[\"count\"]], \"B_n\": [b[\"count\"]]\n",
    "    })\n",
    "\n",
    "results = pd.concat([\n",
    "    summarize_conversion(\"seen_page\"),\n",
    "    summarize_conversion(\"add_cart\"),\n",
    "    summarize_conversion(\"purchased\"),\n",
    "    summarize_conversion(\"add_cart\", lambda d: d[\"seen_page\"]==1),\n",
    "    summarize_conversion(\"purchased\", lambda d: d[\"add_cart\"]==1),\n",
    "    summarize_conversion(\"purchased\", lambda d: d[\"seen_page\"]==1)\n",
    "])\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación:**  \n",
    "Definimos funciones para calcular **intervalos de confianza**, **prueba z de dos proporciones** y usaremos `mannwhitneyu` para revenue.\n",
    "  \n",
    "Cada fila muestra la tasa de conversión, el **lift** del grupo B frente a A, y su **p-value** de la prueba z.  \n",
    "Esto permite identificar qué etapas presentan diferencias estadísticamente significativas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARPU / AOV / Mann-Whitney p: 0.005288962672564268\n"
     ]
    }
   ],
   "source": [
    "# Métricas de revenue\n",
    "rev_stats = (\n",
    "    user_metrics.groupby(\"group\")[\"rev_14d\"]\n",
    "      .agg(n=\"count\", mean=\"mean\", median=\"median\",\n",
    "           p90=lambda s: s.quantile(0.9),\n",
    "           purchasers=lambda s: (s>0).sum())\n",
    ")\n",
    "rev_stats[\"purch_rate\"] = rev_stats[\"purchasers\"]/rev_stats[\"n\"]\n",
    "\n",
    "aov = (\n",
    "    user_metrics[user_metrics[\"rev_14d\"]>0]\n",
    "      .groupby(\"group\")[\"rev_14d\"]\n",
    "      .agg(mean=\"mean\", median=\"median\", p90=lambda s: s.quantile(0.9))\n",
    ")\n",
    "\n",
    "u_stat, p_u = mannwhitneyu(\n",
    "    user_metrics.loc[user_metrics[\"group\"]==\"A\",\"rev_14d\"],\n",
    "    user_metrics.loc[user_metrics[\"group\"]==\"B\",\"rev_14d\"],\n",
    "    alternative=\"two-sided\"\n",
    ")\n",
    "print(\"ARPU / AOV / Mann-Whitney p:\", p_u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretación:**  \n",
    "- **ARPU** (ingreso promedio por usuario) incluye ceros; mide impacto general.  \n",
    "- **AOV** (promedio de compra) mide ticket medio solo de compradores.  \n",
    "- **Mann-Whitney** evalúa diferencia en distribución de ingresos (robusto ante muchos ceros).  \n",
    "Un **p < 0.05** sugiere diferencia significativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Resultados y Conclusiones\n",
    "###  Evaluación de la prueba A/B\n",
    "\n",
    "**1.- Resultados del test**  \n",
    "El nuevo sistema **no mejoró la conversión**.\n",
    "\n",
    "- Menor proporción de vistas, las compras y el ARPU.  \n",
    "- p-values < 0.05 en “purchase” y “ARPU” indican diferencias **estadísticamente significativas** en perjuicio del grupo B.  \n",
    " El sistema de recomendaciones **empeora** el rendimiento comercial.\n",
    "\n",
    "**2.- Prueba z aplicada** \n",
    "\n",
    "Ya fue usada en tu tabla (`z_stat` y `p_value`):\n",
    "\n",
    "- `purchase`: z = −1.99, p = 0.046 → significativa (rechaza H₀).  \n",
    "- Otras etapas: p > 0.05 → sin diferencia estadística.\n",
    "\n",
    "\n",
    "###  Conclusiones generales\n",
    "\n",
    "- **EDA** confirma que los datos estan limpios, sin duplicados ni contaminación, pero con desbalance y una menor muestra.  \n",
    "- **Prueba A/B** muestra que el grupo B tiene peor desempeño en conversión y revenue.  \n",
    "- **Decisión**: no implementar el nuevo embudo; se recomienda analizar causas (interfaz, recomendaciones o fricción en pago).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Envi_proyectos_tripleten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
